je travaille sur l'octro d'une valeur de gage sur les produits structurés, on doit étudier les termsheets et après analayse, donner une VG,  je pourrais avec un script python récupéer sur mon outook tout les termsheets (fichiers PDF) de ces produits structurés, chaque termesheet(produit structuré à un ISIN uniques), j'ai ailleurs un ficher  pour associer  ISIN et Valeur de gage, plus exactement c'est un triplet exemple 50/60/70 ce triplet change selon les caracteristiques du produit structuré.
Chaque termsheet (pdf produit structuré) ne se ressemble pas et a une sructure differente selon les emetteurs

J'aimerais un modèle de machine learning pour apprendre un modele sur ces données que je pourrais récupréer  et ainsi apprendre le modèle à identifier le bon triplet comment faire, modele NLP, IA generative, machine learning, deep learning, je ne sais pas quelle caracteristiques retenir 

dans un premiere temps comment récuper ces pdf et les stockers, et consituer et enrichir au fil du temps ces données

```
import os
import pandas as pd
import numpy as np
import joblib
import re
import win32com.client  # Pour Outlook
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Étape 1: Récupération des termsheets depuis Outlook
def get_termsheets_from_outlook(folder_name="Inbox"):
    outlook = win32com.client.Dispatch("Outlook.Application").GetNamespace("MAPI")
    inbox = outlook.Folders.Item(1).Folders[folder_name]  # Adapter si nécessaire
    messages = inbox.Items
    termsheets = {}
    
    for message in messages:
        if message.Attachments.Count > 0:
            for attachment in message.Attachments:
                if attachment.FileName.endswith(".pdf"):
                    filepath = os.path.join("termsheets", attachment.FileName)
                    attachment.SaveAsFile(filepath)
                    isin = extract_isin_from_filename(attachment.FileName)
                    termsheets[isin] = filepath
    return termsheets

# Étape 2: Extraction de l'ISIN depuis le nom de fichier
def extract_isin_from_filename(filename):
    match = re.search(r"([A-Z]{2}[0-9A-Z]{9}[0-9])", filename)
    return match.group(1) if match else None

# Étape 3: Extraction des caractéristiques du produit depuis le termsheet (Exemple simplifié)
def extract_features_from_termsheet(filepath):
    # Simule l'extraction des données à partir du texte du PDF
    return {
        "maturite": np.random.randint(1, 10),  # Exemple: Maturité en années
        "coupon": np.random.uniform(0, 10),   # Exemple: Coupon en %
        "barriere": np.random.uniform(50, 100) # Exemple: Barrière en %
    }

# Étape 4: Chargement du fichier ISIN ↔ VG
def load_vg_data(csv_file):
    df = pd.read_csv(csv_file)
    return df.set_index("ISIN")["VG"]

# Étape 5: Construction du dataset
def build_dataset(termsheets, vg_data):
    data = []
    for isin, filepath in termsheets.items():
        features = extract_features_from_termsheet(filepath)
        if isin in vg_data:
            features["VG"] = vg_data[isin]
            data.append(features)
    return pd.DataFrame(data)

# Étape 6: Entraînement du modèle
def train_model(data):
    X = data.drop(columns=["VG"])
    y = data["VG"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f"RMSE : {rmse}")
    
    joblib.dump(model, "vg_model.pkl")
    return model

# Étape 7: Prédiction sur un nouveau produit
def predict_vg(model, new_product_features):
    return model.predict([new_product_features])[0]

# Execution complète
def main():
    termsheets = get_termsheets_from_outlook()
    vg_data = load_vg_data("vg_data.csv")
    dataset = build_dataset(termsheets, vg_data)
    model = train_model(dataset)
    
    # Exemple de prédiction
    new_product = extract_features_from_termsheet("example.pdf")
    predicted_vg = predict_vg(model, new_product)
    print(f"Valeur de Gage Prédite: {predicted_vg}")

if __name__ == "__main__":
    main()


```
ISIN : Identifiant unique du produit structuré
maturite : Durée du produit en années
coupon : Taux de coupon en %
barriere : Niveau de barrière en %

VG_50, VG_60, VG_70 : Les valeurs de gage correspondant aux trois scénarios

# . Gestion du dataset et enrichissement
```
import os
import pandas as pd
import numpy as np
import re
import joblib
import win32com.client  # Pour récupérer les termsheets via Outlook

DATASET_FILE = "vg_dataset.csv"  # Fichier où on stocke les données structurées

# Extraction ISIN depuis le nom du fichier
def extract_isin_from_filename(filename):
    match = re.search(r"([A-Z]{2}[0-9A-Z]{9}[0-9])", filename)
    return match.group(1) if match else None

# Simulation d'extraction des caractéristiques depuis un termsheet (à remplacer par de l’OCR si nécessaire)
def extract_features_from_termsheet(filepath):
    return {
        "maturite": np.random.randint(1, 10),  # Exemple: Maturité en années
        "coupon": np.random.uniform(0, 10),   # Exemple: Coupon en %
        "barriere": np.random.uniform(50, 100), # Exemple: Barrière en %
    }

# Chargement du dataset existant
def load_existing_dataset():
    if os.path.exists(DATASET_FILE):
        return pd.read_csv(DATASET_FILE, index_col="ISIN")
    return pd.DataFrame(columns=["ISIN", "maturite", "coupon", "barriere", "VG_50", "VG_60", "VG_70"]).set_index("ISIN")

# Mise à jour avec de nouveaux termsheets
def update_dataset_with_new_termsheets(termsheets):
    dataset = load_existing_dataset()

    for isin, filepath in termsheets.items():
        new_features = extract_features_from_termsheet(filepath)
        
        if isin in dataset.index:
            dataset.loc[isin, ["maturite", "coupon", "barriere"]] = new_features.values()
        else:
            # Simulation de valeurs de gage (à remplacer par les vraies données)
            new_vg_values = np.random.randint(30, 80, size=3)  # Simule VG_50 / VG_60 / VG_70
            dataset.loc[isin] = {**new_features, "VG_50": new_vg_values[0], "VG_60": new_vg_values[1], "VG_70": new_vg_values[2]}
    
    dataset.to_csv(DATASET_FILE)
    print(f"Dataset mis à jour avec {len(termsheets)} nouveaux produits.")
    return dataset

```

# B. Ajout automatique des nouveaux produits via Outlook

```
def get_termsheets_from_outlook(folder_name="Inbox"):
    outlook = win32com.client.Dispatch("Outlook.Application").GetNamespace("MAPI")
    inbox = outlook.Folders.Item(1).Folders[folder_name]  # Adapter selon la structure Outlook
    messages = inbox.Items
    termsheets = {}

    for message in messages:
        if message.Attachments.Count > 0:
            for attachment in message.Attachments:
                if attachment.FileName.endswith(".pdf"):
                    filepath = os.path.join("termsheets", attachment.FileName)
                    attachment.SaveAsFile(filepath)
                    isin = extract_isin_from_filename(attachment.FileName)
                    if isin:
                        termsheets[isin] = filepath
    return termsheets


```

# C. Exécution complète : Mise à jour et enrichissement
```
def main():
    termsheets = get_termsheets_from_outlook()
    dataset = update_dataset_with_new_termsheets(termsheets)
    print(dataset.head())  # Afficher un aperçu du dataset

if __name__ == "__main__":
    main()


```