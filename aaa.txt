# üöÄ Utiliser un mod√®le GGUF avec Ollama sur **Windows** (proc√©dure compl√®te)

> üéØ Objectif : T√©l√©charger un mod√®le `.gguf` depuis Hugging Face et le rendre utilisable avec Ollama localement.

---

## ‚úÖ Pr√©-requis

### 1. Avoir **Ollama** install√©

- Va sur [https://ollama.com](https://ollama.com)
- T√©l√©charge l‚Äôinstalleur Windows
- Installe-le comme n'importe quel logiciel Windows

#### V√©rification :

- Ouvre **PowerShell**
- Tape `ollama`  
‚Üí Tu devrais voir la liste des commandes disponibles.

---

## üß† √âtapes d√©taill√©es

---

### üü© √âtape 1 : T√©l√©charger un mod√®le GGUF depuis Hugging Face

1. Va sur [https://huggingface.co](https://huggingface.co)
2. Cherche un mod√®le GGUF, par exemple :
   ```
   TheBloke Llama2 GGUF
   ```
3. Clique sur un d√©p√¥t, par exemple :
   - https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF
4. Va dans l‚Äôonglet **Files and versions**
5. T√©l√©charge un fichier comme :
   ```
   llama-2-7b-chat.Q4_K_M.gguf
   ```

üí° **Important :** Prends un fichier avec `chat` ou `instruct` dans le nom (pas `base`).

---

### üü© √âtape 2 : Cr√©er un dossier pour le mod√®le

Avec **PowerShell**, tape :

```powershell
mkdir $env:USERPROFILE\.ollama\models\llama2-custom
```

Tu peux aussi le cr√©er manuellement dans l‚Äôexplorateur :
```
C:\Users\TonNomUtilisateur\.ollama\models\llama2-custom
```

---

### üü© √âtape 3 : D√©placer le fichier `.gguf`

D√©place le fichier t√©l√©charg√© dans le dossier :
```
C:\Users\TonNomUtilisateur\.ollama\models\llama2-custom\
```

Tu devrais avoir par exemple :
```
C:\Users\TonNomUtilisateur\.ollama\models\llama2-custom\llama-2-7b-chat.Q4_K_M.gguf
```

---

### üü© √âtape 4 : Cr√©er le fichier `Modelfile` (sans extension)

1. Ouvre **Notepad**
2. Colle ce contenu (exemple simple) :

```
FROM gguf
PARAMETER model llama-2-7b-chat.Q4_K_M.gguf
```

3. Enregistre sous :
   - **Nom du fichier :** `"Modelfile"` (avec guillemets)
   - **Type :** Tous les fichiers
   - **Encodage :** UTF-8
   - **Emplacement :** Dans le dossier `llama2-custom`

‚úÖ R√©sultat : tu dois avoir un fichier `Modelfile` **sans extension**, dans :
```
C:\Users\TonNomUtilisateur\.ollama\models\llama2-custom\
```

---

### üü© √âtape 5 : Cr√©er le mod√®le dans Ollama

Dans **PowerShell**, tape :

```powershell
ollama create llama2-custom -f $env:USERPROFILE\.ollama\models\llama2-custom\Modelfile
```

Tu verras que le mod√®le est en train d‚Äô√™tre construit.

---

### üü© √âtape 6 : Lancer le mod√®le

Toujours dans PowerShell :

```powershell
ollama run llama2-custom
```

Tu peux maintenant lui parler depuis ton terminal.

---

## üí¨ Bonus : Ajouter un prompt syst√®me par d√©faut

Tu peux personnaliser le `Modelfile` avec un comportement assistant :

```
FROM gguf
PARAMETER model llama-2-7b-chat.Q4_K_M.gguf
TEMPLATE """<|system|>
You are a helpful assistant.
<|user|>
{{ .Prompt }}
<|assistant|>"""
```

---

## üß™ Test rapide

```bash
ollama run llama2-custom
```

Puis tape :
```
Explique-moi comment faire une sauce carbonara traditionnelle.
```

---

## üßØ En cas de souci

- **Erreur : fichier introuvable** ‚Üí V√©rifie le nom du fichier `.gguf` dans le `Modelfile`
- **Le fichier Modelfile est `.txt`** ‚Üí Renomme-le pour supprimer l‚Äôextension
- **Probl√®me de RAM** ‚Üí Utilise une version compress√©e du mod√®le (`Q4`, `Q5`‚Ä¶)

---

## üôã‚Äç‚ôÇÔ∏è Besoin d‚Äôaide ?

Envoie-moi le **nom exact** de ton fichier `.gguf` et je te g√©n√®re le `Modelfile` pr√™t √† l‚Äôemploi.

# autre

Bonjour, j'ai des probl√®mes pour convertir mes fichiers GGUF en ollama. Voici ce que j'ai fait :

T√©l√©charg√© Smart-Lemon-Cookie-7B-Q4_K_M.ggufdepuis https://huggingface.co/FallenMerick/Smart-Lemon-Cookie-7B-GGUF/blob/main/Smart-Lemon-Cookie-7B-Q4_K_M.gguf
J'ai cr√©√© mon Modelfilepour contenir uniquement :

FROM ~/Downloads/Smart-Lemon-Cookie-7B-Q4_K_M.gguf


Ran ollama create Smart-Lemon-Cookie-7B -f '~/Downloads/Modelfile'qui a abouti √† :

# autre 2

√âtape 2 : Configurer le r√©pertoire Ollama
Ouvrez votre terminal et acc√©dez au r√©pertoire d'installation d'Ollama :
cd ~/ollama/models


Nous allons ensuite cr√©er un Modelfileavec le contenu suivant :

Fichier mod√®le
FROM ./downloads/mistrallite.Q4_K_M.gguf

Nous construisons ensuite un mod√®le Ollama en utilisant la commande suivante :

ollama create mistrallite -f Modelfile	

Et maintenant, voyons si nous pouvons amener le mod√®le √† nous dire tout sur l'outil de visualisation Grafana :

ollama run mistrallite "What is Grafana?"

# autre 3
T√©l√©chargez le mod√®le .gguf que vous voulez. Pour cet exemple, il se trouve dans le dossier "T√©l√©chargements" standard de Windows

Cr√©ez un fichier Modelfile.txt dans C:/Users/YourWindowsName

Ouvrez le fichier Modelfile.txt et ins√©rez "from C:\Users\YourWindowsName\Downloads\MODELNAME.gguf"

Enregistrez et fermez Modelfile.txt

Renommez "Modelfile.txt" en "Modelfile"

Ouvrez CMD et tapez "ollama create NAMEYOUWANT -f Modelfile"

Attendez la fin	

# Autre 4

Ex√©cution du mod√®le dans Ollama
Assurez-vous que votre ollama est correctement install√© en ouvrant l'invite de commande et en ex√©cutant ollama -v.

Ensuite, suivez ces √©tapes :

D√©placez le fichier t√©l√©charg√© Meta-Llama-3.1-8B-Instruct-Q4_K_M.ggufdans ce dossier C:\Users\YOUR_USER_NAME\.ollama\models de vos fen√™tres.
Cr√©ez un nouveau dossier appel√© modelfiles √† ce chemin C:\Users\YOUR_USER_NAME\.ollama
Dans le dossier modelfilesMeta-Llama , cr√©ez un fichier nomm√© (vous pouvez utiliser le nom de votre choix) et ouvrez-le dans un √©diteur de texte. Ne lui attribuez pas d'extension de fichier, comme .txt ou autre.
Dans le fichier, indiquez le chemin d'acc√®s au .gguffichier t√©l√©charg√©. Dans notre cas, le chemin est * **C:\Users\YOUR_USER_NAME\.ollama\models\Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf *.

Donc dans le Meta-Llamafichier nous allons √©crire :
DE C:\Users\VOTRE_NOM_D'UTILISATEUR.ollama\models\Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

Enregistrez maintenant le fichier et ouvrez l'invite de commande dans le r√©pertoire modelfiles . (Appuyez simplement sur ctrl+l, tapez cmdet appuyez sur Entr√©e pour ouvrir l'invite de commande.)

Tapez maintenant
ollama create meta-llama -f C:\Users\YOUR_USER_NAME\.ollama\modelfiles\Meta-Llama

# fin

O√π sont stock√©s les mod√®les Ollama ?
Les mod√®les Ollama sont stock√©s dans le ~/.ollama/modelsr√©pertoire de votre machine locale. Ce r√©pertoire contient tous les mod√®les que vous avez t√©l√©charg√©s ou cr√©√©s. Ils sont stock√©s dans un sous-r√©pertoire nomm√© blobs.

Lorsqu'un mod√®le est t√©l√©charg√© √† l'aide de la ollama pullcommande, il est stock√© dans le ~/.ollama/models/manifests/registry.ollama.ai/library/<model family>/latestr√©pertoire. Si vous sp√©cifiez une version particuli√®re lors de l'extraction, le mod√®le est stock√© dans le ~/.ollama/models/manifests/registry.ollama.ai/library/<model family>/<version>r√©pertoire.

Si vous souhaitez importer un mod√®le personnalis√©, vous pouvez cr√©er un fichier Modelfileavec une FROMinstruction sp√©cifiant le chemin d'acc√®s local au mod√®le √† importer. Apr√®s avoir cr√©√© le mod√®le dans Ollama √† l'aide de la ollama createcommande, vous pouvez l'ex√©cuter avec cette ollama runm√™me commande.

Veuillez noter que ces mod√®les peuvent occuper un espace disque important. Par exemple, le mod√®le 13b Llama2 n√©cessite 32 Go de stockage. Il est donc important de g√©rer efficacement votre espace de stockage, surtout si vous travaillez avec plusieurs mod√®les volumineux.